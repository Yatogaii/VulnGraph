"""Pydantic models for Planner's Plan and Step and helpers to parse LLM output.

This module replaces the old TypeScript-like interface definitions with
Pydantic models that validate inputs and provide a robust parser for converting
large language model responses (often wrapped in text or markdown) into
typed Plan objects.

Helper functions:
- extract_json_from_text(text) -> str | None : returns a likely JSON substring
  from the given text (fenced code blocks, first balanced object, etc.).
- repair_json_string(s) -> str : attempts to fix common LLM JSON formatting
  issues (remove comments, replace single quotes, remove trailing commas).
- parse_plan_from_llm(text, *, raise_on_error=True) -> Plan | None: top-level
  helper that extracts, repairs, loads JSON and validates into Plan model.

Pydantic v2+ is used throughout (see pyproject.toml). Models are strict and
forbid unknown fields to adhere to the prompt contract.
"""
from __future__ import annotations

import json
import re
from typing import List, Literal, Optional

from pydantic import BaseModel, ConfigDict, ValidationError


class Step(BaseModel):
    """One executable step in a Plan.

    Fields:
      - step_type: One of: 'asset_analysis', 'vuln_analysis', 'reporting'
      - title: Short human readable title
      - description: Detailed instructions for the worker agent
      - target: The asset, CVE or scope this step targets
    """

    step_type: Literal["asset_analysis", "vuln_analysis", "reporting"]
    title: str
    description: str
    target: str

    # Extra fields should not be allowed â€“ keep the model strict to match the
    # prompt contract.
    model_config = ConfigDict(extra="forbid")


class Plan(BaseModel):
    """Full plan as generated by the planner LLM.

    Fields match the `Plan` interface in the planner prompt exactly.
    """

    locale: str
    has_enough_context: bool
    finish_plan: bool
    thought: str
    title: str
    steps: List[Step]

    model_config = ConfigDict(extra="forbid")


def _extract_json_from_text(text: str) -> Optional[str]:
    """Try to extract a JSON substring from a possibly noisy LLM output.

    The function attempts the following heuristics in order:
    1. Find a fenced code block indicating JSON (```json ... ``` or ``` ... ```)
    2. Find the first balanced JSON object starting with a '{'
    3. If none found, return None
    """
    if not text:
        return None

    # 1) Fenced code block (prefer JSON-specifier but accept generic fences)
    fence_match = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", text, re.IGNORECASE)
    if fence_match:
        return fence_match.group(1).strip()

    # 2) Balanced first JSON object (careful with nested braces)
    start = text.find("{")
    if start == -1:
        return None

    depth = 0
    in_string = False
    escape = False
    for i in range(start, len(text)):
        ch = text[i]
        if in_string:
            if escape:
                escape = False
            elif ch == "\\":
                escape = True
            elif ch == '"':
                in_string = False
            continue

        if ch == '"':
            in_string = True
            continue
        if ch == '{':
            depth += 1
        elif ch == '}':
            depth -= 1
            if depth == 0:
                return text[start : i + 1]
    return None


def _repair_json_string(s: str) -> str:
    """Attempt to repair common JSON issues LLMs produce.

    Fixes:
    - Remove single-line and block comments (// and /* */)
    - Convert single quoted keys/values to double quotes as a fallback
    - Remove trailing commas before } or ]
    - Strip surrounding markdown markers or backticks
    """
    if not s:
        return s

    # Remove Markdown fences if present
    s = re.sub(r"^\s*`+\s*", "", s)
    s = re.sub(r"`+\s*$", "", s)

    # Remove comments (// or /* */)
    s = re.sub(r"//.*?$", "", s, flags=re.MULTILINE)
    s = re.sub(r"/\*.*?\*/", "", s, flags=re.DOTALL)

    # Remove trailing commas: `, }` -> `}` and `, ]` -> `]`
    s = re.sub(r",\s*([}\]])", r"\1", s)

    # If JSON decode still fails, LLMs commonly use single quotes; attempt a
    # conservative single->double quote replacement where appropriate. This
    # is a heuristic and may still fail for complex cases.
    single_quotes_likely = "'" in s and '"' not in s
    if single_quotes_likely:
        # Avoid replacing quotes inside nested JSON fragments; a simple
        # blanket replace is the pragmatic fallback here.
        s = s.replace("'", '"')

    return s


def parse_plan_from_llm(text: str, *, raise_on_error: bool = True) -> Optional[Plan]:
    """Parse an LLM response into a Plan object.

    This function is robust to common LLM output formats: pure JSON, JSON
    inside markdown code blocks, or verbose text that contains a JSON segment.
    It attempts to extract JSON, repair common issues, and finally validate the
    final payload against the strict Plan Pydantic model.

    If `raise_on_error` is True, JSON parsing or validation errors are raised
    to help debugging; otherwise, None is returned on failure.
    """
    json_str = _extract_json_from_text(text)
    if not json_str:
        # Maybe the whole text is JSON, try to parse as-is
        json_str = text.strip()
    if not json_str:
        if raise_on_error:
            raise ValueError("No JSON object found in LLM response")
        return None

    tried_repair = False
    payload = None
    for attempt in range(2):
        try:
            payload = json.loads(json_str)
            break
        except json.JSONDecodeError:
            if attempt == 0:
                json_str = _repair_json_string(json_str)
                tried_repair = True
                continue
            if raise_on_error:
                raise
            return None

    try:
        plan = Plan.model_validate(payload)
        return plan
    except ValidationError as e:
        if raise_on_error:
            # Re-raise with a helpful message
            raise
        return None


__all__ = ["Plan", "Step", "parse_plan_from_llm"]